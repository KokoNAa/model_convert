name: Convert Yolo Detect Models

# 触发工作流的事件
on:
  workflow_dispatch:
    inputs:
      pt_model:
        description: "URL/repo path to your .pt model"
        required: true
        default: "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt"
  push: 
    branches: [master]
  pull_request:
    branches: [master]

jobs:
  pt2onnx:
    strategy:
      matrix:
        runs-on: [ubuntu-22.04]
    runs-on: ${{ matrix.runs-on }}
    container:
      image: ultralytics/ultralytics:8.3.89-cpu
      options: --privileged

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 1000
        fetch-tags: true

    - name: Prepare workspace
      run: |
        mkdir -p yolo/onnx
        cd yolo/onnx

    - name: Fetch model (custom or default)
      run: |
        CUSTOM_MODEL="${{ github.event.inputs.pt_model }}"
        
        # 检查是否提供自定义模型
        if [[ "$CUSTOM_MODEL" != "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt" ]]; then
          echo "Using custom model: $CUSTOM_MODEL"
          
          # 检查模型来源类型
          if [[ $CUSTOM_MODEL == http* ]]; then
            wget -O custom.pt "$CUSTOM_MODEL"
          elif [[ -f "../$CUSTOM_MODEL" ]]; then
            cp "../$CUSTOM_MODEL" custom.pt
          else
            echo "::error::Could not locate custom model: $CUSTOM_MODEL"
            exit 1
          fi
          
          MODEL_PATH=custom.pt
        else
          echo "Using default model"
          wget "$CUSTOM_MODEL" -O default.pt
          MODEL_PATH=default.pt
        fi

        echo "MODEL_PATH=$MODEL_PATH" >> $GITHUB_ENV

    - name: Convert to ONNX
      run: |
        apt-get update && apt install -y --no-install-recommends wget
        pip install onnxsim
        
        cd ..
        python export_det_v11.pyc -w onnx/$MODEL_PATH --sim
        
        # 重命名为标准格式
        mv *.onnx onnx/model.onnx

    - name: Upload artifact
      uses: actions/upload-artifact@v4
      with:
        name: onnx_artifacts
        path: yolo/onnx/model.onnx

  onnx2rknn:
    needs: [pt2onnx]
    strategy:
      matrix:
        runs-on: [ubuntu-22.04]
    runs-on: ${{ matrix.runs-on }}
    container:
      image: kaylor/rk3588_onnx2rknn:2.3.2
      options: --privileged

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 1000
        fetch-tags: true

    - name: Download artifacts from pt2onnx
      uses: actions/download-artifact@v4
      with:
        name: onnx_artifacts
        path: onnx_artifacts

    - name: Run build script
      run: |
        SRC_PATH=$(pwd)
        cd yolo
        mkdir -pv rknn
        cp -vr ${SRC_PATH}/onnx_artifacts/*.onnx ./rknn/
        python convert.pyc rknn/yolo.onnx rk3588 i8 rknn/yolo.rknn


    - name: Upload artifact
      uses: actions/upload-artifact@v4
      with:
        name: rknn_artifacts
        path: yolo/rknn/*.rknn

  onnx2om:
    needs: [pt2onnx]
    strategy:
      matrix:
        runs-on: [ubuntu-22.04]
    runs-on: ${{ matrix.runs-on }}
    container:
      image: kaylor/atc
      options: --privileged

    steps:
    - name: Download artifacts from pt2onnx
      uses: actions/download-artifact@v4
      with:
        name: onnx_artifacts
        path: onnx_artifacts

    - name: Run build script
      shell: bash
      run: |
        SRC_PATH=$(pwd)
        mkdir -pv om
        cp -vr ${SRC_PATH}/onnx_artifacts/*.onnx ./om/
        source /usr/local/Ascend/ascend-toolkit/set_env.sh
        export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/x86_64-linux/devlib/:$LD_LIBRARY_PATH
        cd om
        atc --model=yolo.onnx --framework=5 --output=yolo --soc_version=Ascend310B4


    - name: Upload artifact
      uses: actions/upload-artifact@v4
      with:
        name: om_artifacts
        path: om/*.om
